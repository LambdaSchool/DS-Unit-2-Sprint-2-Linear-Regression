{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krsmith/DS-Unit-2-Sprint-2-Linear-Regression/blob/master/module3-gradient-descent/Gradient_Descent_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Qhm0Y_jqXKRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Implementation Challenge!!\n",
        "\n",
        "## Use gradient descent to find the optimal parameters of a **multiple** regression model. (We only showed an implementation for a bivariate model during lecture.)\n",
        "\n",
        "A note: Implementing gradient descent in any context is not trivial, particularly the step where we calculate the gradient will change based on the number of parameters that we're trying to optimize for. You will need to research what the gradient of a multiple regression model looks like. This challenge is pretty open-ended but I hope it will be thrilling. Please work together, help each other, share resources and generally expand your understanding of gradient descent as you try and achieve this implementation. \n",
        "\n",
        "## Suggestions:\n",
        "\n",
        "Start off with a model that has just two $X$ variables You can use any datasets that have at least two x variables. Potential candidates might be the blood pressure dataset that we used during lecture on Monday: [HERE](https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/excel/mlr02.xls) or any of the housing datasets. You would just need to select from them the two varaibles $x$ variables and one y variable that you want to work with that you most want to work with. \n",
        "\n",
        "Use Sklearn to find the optimal parameters of your model first. (like we did during the lecture.) So that you can compare the parameter estimates of your gradient-descent linear regression to the estimates of OLS linear regression. If implemented correctly they should be nearly identical.\n",
        "\n",
        "Becoming a Data Scientist is all about striking out into the unknown, getting stuck and then researching and fighting and learning until you get yourself unstuck. Work together! And fight to take your own learning-rate fueled step towards your own optimal understanding of gradient descent! \n"
      ]
    },
    {
      "metadata": {
        "id": "_tWzF6IqXIIq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BFuMzJBdjar6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9deea3f3-7436-4811-f257-16f0c5cf9a2b"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/excel/mlr02.xls')\n",
        "df = df.rename(index=str, columns={\"X1\": \"y\", \"X2\": \"age\", \"X3\": \"weight\"})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>132</td>\n",
              "      <td>52</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143</td>\n",
              "      <td>59</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>67</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>162</td>\n",
              "      <td>73</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154</td>\n",
              "      <td>64</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y  age  weight\n",
              "0  132   52     173\n",
              "1  143   59     184\n",
              "2  153   67     194\n",
              "3  162   73     211\n",
              "4  154   64     196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "3_2MogQ6lIpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "766117a0-4e7b-4842-dce3-fb029a046507"
      },
      "cell_type": "code",
      "source": [
        "#Working with Bivariate first to make sure I know what's going on.\n",
        "\n",
        "# First we'll calculate our parameters using sklearn to see how close our \n",
        "# Gradient Descent Method gets. \n",
        "\n",
        "# Create X matrix and y vector\n",
        "X = df['age'].values[:, np.newaxis]\n",
        "\n",
        "# If we don't do this our GD stuff will break\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Matrix version makes cool linalg tricks possible\n",
        "X_linalg = np.c_[np.ones(X.shape[0]), X] \n",
        "\n",
        "# print(X_linalg)\n",
        "\n",
        "# Boring y variable list\n",
        "y = df['y'].values\n",
        "\n",
        "# Fit Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Assign coefficient and intercept to variables (beta_1, and beta_0)\n",
        "beta_1 = model.coef_[0]\n",
        "beta_0 = model.intercept_\n",
        "\n",
        "print(\"beta_1: \", beta_1)\n",
        "print(\"beta_0: \", beta_0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta_1:  12.715856751330023\n",
            "beta_0:  150.0909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w_a2uR3LlkH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "2b55216e-adf2-42a6-ccdf-dc85fb639946"
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(X,y)\n",
        "\n",
        "plt.ylabel(\"Blood Pressure\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.title(\"Blood Pressure and Age\")\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFnCAYAAACl2jDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X9cVHW+P/DX/GBmUgacgUHL/K6m\nommo+KM0NQxB0DZqA+WHQ3nXvZv5ozRaLbebGpXhWo9dEbfwdrWgu/kjS8sUM/xB5ZIsZGL5mFxc\nL1IJyG9HhmE43z+8nhs5MAjMDJzzej4ePR6e8zkz835zHruvOZ9zzhyFIAgCiIiISHKU3i6AiIiI\n3IMhT0REJFEMeSIiIoliyBMREUkUQ56IiEiiGPJEREQSxZAnugkjRoxAZGQkoqOjERUVhd/97nco\nLS0FAOTn5yMyMrLbPmvv3r1ITk6+Yf3FixcxYsQIREdHi3XMnz8f3377bbd9dm/T1t/quubmZkRH\nR+O3v/2tB6si8j6GPNFNysrKwsGDB5GTk4M777wTL7/8ssdrUKlUOHjwoFjH/PnzsWTJEjQ1NXm8\nlt4gLy8PkydPxuXLl3Hp0iVvl0PkMQx5oi6YPHmyeCT/czabDS+88AKioqIwe/ZsvPrqq3A4HACA\ns2fPIiEhAdHR0XjooYeQl5cHAGhpacGLL76IGTNmIC4uDmfPnu1wHXPmzEFjYyNKSkqQn5+PhIQE\nPPXUU0hJSQEAHD58GA8++CBmzpyJ3/72t6iqqgIAWCwWxMfH44EHHsCsWbOQnZ3d7vpnn30WW7Zs\nET/358vh4eHYvHkzoqKi8MMPP+Cnn37CokWLEBUVhaioKBw7dsxp7SUlJUhMTMTs2bMRGRmJjz/+\nWBwbMWIEPvzwQzz88MOYNm0atm/f3qm/1QcffIDo6GjMmTMHe/fuFde3tLQgNTUVU6dORWJiIjIz\nM8UZgbq6OvzhD39AVFQUZs6ciffff7/D+4Oop2DIE3VSU1MT9u3bh/Dw8BvG3n77bfz000/Yv38/\nPvjgAxQUFODjjz9GS0sLnn76aZjNZhw8eBAvvfQSUlJS0NDQgLy8PHzxxRfYv38/srOzUVBQcFP1\nOBwOaDQaAMC3336LhIQEvPbaaygtLcXKlSvx2muv4bPPPsM999yDtWvXAgA2b96MhIQE7N+/H++9\n9x6+/PJLNDU1tbnelUuXLiEnJwe33XYbVq1ahZEjRyInJweZmZlYuXIlqqurb3jNhg0bcP/99+PA\ngQN45ZVX8Mc//hF2u10cP3fuHD788ENs2bIFr7/+OhwOx039rWpqanD27Fncc889+PWvf42PPvpI\nHDt27BiOHz+OQ4cO4a9//Ss++OADcezVV1+FUqnEgQMHsGvXLqSnp8Nisbj8GxD1JAx5opuUnJyM\n6OhoTJ06FadPn8YjjzxywzZHjx7FvHnzoFarodPp8OCDD+KLL77AxYsXUVlZiQceeAAAEBISgttu\nuw2nT5/GyZMnERYWhr59+0Kn02H27NkdqkcQBOzYsQP9+/fH4MGDAQA6nQ5TpkwBABw/fhx33303\ngoODAQAJCQnIzc2Fw+FAQEAAcnJycObMGRgMBmzZsgUajabN9a7MmDEDAGC1WpGfn48FCxYAAH71\nq19hwoQJTo/mt2zZgoULFwIAJkyYAJvNhoqKCnH8oYceAgCMHj0aNpsNly9fvqm/1f79+zFr1iwo\nFAoMHDgQ/v7+KC4uBgAUFBRgxowZ6Nu3L/r16yfuFwA4cuQIHn30USiVShiNRkRGRuLQoUMu/wZE\nPYna2wUQ9TZZWVkYMGAAAODkyZNITk7Gnj17Wm1TVVUFf39/cdnf3x+XL19GVVUV9Ho9FAqFOObn\n54eqqirU1tYiKCio1fq2OBwOREdHA7gW8sOGDcOWLVugVCrFz7uuvr4eBQUF4vYA4Ovri5qaGjzz\nzDN48803sXz5cthsNjz++OOYP39+m+tduf659fX1EAQBCQkJ4pjVasXkyZNveE1eXh7++te/orq6\nGgqFAoIgoKWlRRzX6/UArl2HAFybYr+Zv9UHH3yAkpISvPfeewAAu92ODz/8EHfddRfq6urQv39/\ncduf/7u+vh7Lly8XP9dms7X6GxL1Bgx5oi6YNGkSbrvtNvzjH/+A0WgU1wcGBqKmpkZcrqmpQWBg\nIAICAlBbWwtBEMSgr6mpQUBAAPz8/FBfXy++5vp5c2euX3jXEUFBQbj33nuxadMmp+NPP/00nn76\naXzzzTf493//d9x7770YMmSI0/VKpbJVANfW1jp9z4CAAKhUKrz//vvo27dvm7XZ7XYsX74cf/7z\nnxEWFoampiaMGTPGZU8d/Vv985//RENDAwoLC1ttGxMTg1WrVsHX1xdWq1Uc+/kMQlBQEDIyMsQZ\nEKLeiNP1RF1w/vx5nD9/HnfccUer9TNmzMDu3bvhcDhgtVqxd+9ehIWF4fbbb8eAAQPwySefAAAK\nCwtRWVmJMWPGIDQ0FJ9//jmuXr2Kq1evdjjEXZk2bRoKCgrECwS/+eYbvPTSSwCARYsW4fvvvwcA\nBAcHw9fXFwqFos31JpNJvMittLS0VXj+nFqtRlhYmHj0fPXqVTz33HP48ccfW2139epVWK1W3HXX\nXQCuXcvg4+PTKnid6ejfas+ePYiIiGi1zmg0YvDgwTh+/DhCQkJw9OhRNDY2oq6uDgcOHBC3Cw8P\nF+tvbm7GK6+8gjNnzrRbF1FPwyN5opuUnJwsTuFqNBqsW7cOI0aMQH5+fqttSktL8cADD0ChUCA6\nOhqzZ8+GQqHA66+/jjVr1mDz5s245ZZb8Je//AV9+vTB/fffj6NHjyI6OhqBgYEICwu76YvvnAkK\nCkJqaiqWLFkCu92Ovn37YvXq1QAAs9mMlJQU8UK3pKQkDB48uM318+bNw9KlSzFr1iyMGjUKUVFR\nbX7u2rVrsWbNGuzatQsAEBMTg1tvvbXVNn5+fvjd736Hhx9+GAEBAXjiiScQERGBRYsWtbrK/pc6\n8rdyOBzYt28f0tPTb3h9REQE9u7di9dee018n1/96leYPXs2Tpw4AQBYvnw51q1bJ/Y4ffp0jBgx\not2/NVFPo+Dz5IlIzn5+6uTdd9/Fl19+iYyMDC9XRdQ9OF1PRLL13XffYebMmaitrUVzczMOHTqE\ncePGebssom7j1ul6i8WCxYsXY8GCBTCbzXjyySfF+2Rramowbtw4pKam4j//8z9x8OBBKBQKLF26\nFGFhYe4si4gIAHDnnXfi4YcfxiOPPAKVSoVx48bBbDZ7uyyibuO26Xqr1YrHH38cgwcPxogRI274\nH85zzz2HxMREGAwGPPXUU3jvvffQ0NCApKQk7N+/XzznSURERJ3jtul6jUaDrVu3trqX9bqSkhLU\n19djzJgxyM/Px/Tp06HRaGA0GjFw4ECcO3fOXWURERHJhttC/vovfTnzzjvviEf2lZWVre4vNhqN\nre5VJSIios7x+IV3TU1N+Mc//uH0l6+Aa1e6utLc7OjusoiIiCTH4/fJnzx5stUvWgUFBeH8+fPi\n8qVLl5xO8f9cdXX7P5RhMulRUVHf7jZSJdfe5do3wN7l2Ltc+wbk27vJpO/U6zx+JH/69GmMHDlS\nXJ48eTKOHj2KpqYmXLp0CeXl5Rg2bJinyyIiIpIctx3JFxcXIy0tDWVlZVCr1cjJyUF6ejoqKirw\n//7f/xO3u+222zBv3jyYzWYoFAqsXbtWfMgGERERdV6v/MU7V1M1cp3OAeTbu1z7Bti7HHuXa9+A\nfHvvNdP1RERE5BkMeSIiIoliyBMREUkUQ56IiEiiGPJERETdxGZ3oLzaCpu9Z/xom8d/DIeIiEhq\nHC0t2JF7DkWWClTV2WD00yI02IT48GFQefG2cIY8ERFRF+3IPYfDBRfF5ct1NnE5KSLYW2Vxup6I\niKgrbHYHiizOH6xWZKn06tQ9Q56IiKgLahtsqKqzOR2rrm9EbYPzMU9gyBMREXWBv68WRj+t0zGD\nXgd/X+djnsCQJyIi6gKtjwqhwSanY6HBgdD6qDxc0f/hhXdERERdFB9+7empRZZKVNc3wqDXITQ4\nUFzvLQx5IiKiLlIplUiKCEZs2FDUNtjg76v16hH8dQx5IiKibqL1USHI0MfbZYh4Tp6IiEiiGPJE\nREQSxZAnIiKSKIY8ERGRRDHkiYhIknraE+G8gVfXExGRpPTUJ8J5A0OeiIgkpac+Ec4b5PWVhoiI\nJK0nPxHOGxjyREQkGT35iXDewJAnIiLJ6MlPhPMGhjwREUlGT34inDe49cI7i8WCxYsXY8GCBTCb\nzbDb7Xj22Wdx4cIF9O3bF5s2bYK/vz9Gjx6N8ePHi6/bvn07VCp57QgiIuoePfWJcN7gtpC3Wq1I\nTU3FlClTxHU7d+6EwWDAa6+9hh07dqCgoAAzZ86Er68vsrKy3FUKERHJSE99Ipw3uG26XqPRYOvW\nrQgKChLXHTlyBDExMQCA+Ph4zJw5010fT0REMnf9iXByDXjAjSGvVquh0+larSsrK8Px48eRnJyM\nFStWoKamBgDQ1NSElJQUJCQkYNu2be4qiYiISFY8+mM4giBgyJAhWLp0KbZs2YI333wTq1atwsqV\nKxETEwOFQgGz2YyJEyciJCSkzfcxGPpArW7/m5nJpO/u8nsNufYu174B9i5Hcu0bkHfvN8ujIR8Y\nGIhJkyYBAKZNm4b09HQAQGJiorjN5MmTYbFY2g356mpru59jMulRUVHfDRX3PnLtXa59A+xdjr3L\ntW9Avr139ouNR2+hu++++5CXlwcAOHPmDIYMGYKSkhKkpKRAEAQ0NzejsLAQw4cP92RZREREkuS2\nI/ni4mKkpaWhrKwMarUaOTk52LhxI15++WXs3r0bffr0QVpaGgIDAzFgwADExcVBqVQiPDwcY8aM\ncVdZREREsqEQBEHwdhE3y9VUjVyncwD59i7XvgH2Lsfe5do3IN/ee8V0PREREXkOQ56IiEiiGPJE\nREQSxZAnIiKSKIY8ERGRRDHkiYiIJIohT0REJFEMeSIiIoliyBMREUkUQ56IiEiiGPJEREQSxZAn\nIiL6BZvdgfJqK2x2h7dL6RKPPk+eiIioJ3O0tGBH7jkUWSpQVWeD0U+L0GAT4sOHQaXsfcfFDHki\nIqL/tSP3HA4XXBSXL9fZxOWkiGBvldVpve9rCRERkRvY7A4UWSqcjhVZKnvl1D1DnoiICEBtgw1V\ndTanY9X1jahtcD7WkzHkiYiIAPj7amH00zodM+h18Pd1PtaTMeSJiIgAaH1UCA02OR0LDQ6E1kfl\n4Yq6jhfeERER/a/48GEArp2Dr65vhEGvQ2hwoLi+t2HIExER/S+VUomkiGDEhg1FbYMN/r7aXnkE\nfx1DnoiI6Be0PioEGfp4u4wu4zl5IiIiiWLIExERSRRDnoiISKIY8kRERBLl1pC3WCyIiIhAdnY2\nAMButyMlJQVxcXF47LHHUFtbCwDYt28fYmNjMXfuXOzatcudJREREcmG20LearUiNTUVU6ZMEdft\n3LkTBoMBu3fvxpw5c1BQUACr1YqMjAxs374dWVlZePvtt1FTU+OusoiIiGTDbSGv0WiwdetWBAUF\nieuOHDmCmJgYAEB8fDxmzpyJU6dOISQkBHq9HjqdDuPHj0dhYaG7yiIiIpINt4W8Wq2GTqdrta6s\nrAzHjx9HcnIyVqxYgZqaGlRWVsJoNIrbGI1GVFQ4fwoQERERdZxHfwxHEAQMGTIES5cuxZYtW/Dm\nm29i1KhRN2zjisHQB2p1+79AZDLpu1RrbybX3uXaN8De5UiufQPy7v1meTTkAwMDMWnSJADAtGnT\nkJ6ejhkzZqCyslLcpry8HOPGjWv3faqrre2Om0x6VFTUd73gXkiuvcu1b4C9y7F3ufYNyLf3zn6x\n8egtdPfddx/y8vIAAGfOnMGQIUMwduxYnD59GnV1dbhy5QoKCwsxceJET5ZFREQkSW47ki8uLkZa\nWhrKysqgVquRk5ODjRs34uWXX8bu3bvRp08fpKWlQafTISUlBQsXLoRCocCSJUug13Mqhoh6F5vd\nIYkHmpC0KISOnATvYVxN1ch1OgeQb+9y7Rtg797u3dHSgh2551BkqUBVnQ1GPy1Cg02IDx8GldI9\nk6U9oW9vkWvvnZ2u51PoiIi6YEfuORwuuCguX66zictJEcHeKosIAH/Wloio02x2B4oszm/5LbJU\nwmZ3eLgiotYY8kREnVTbYENVnc3pWHV9I2obnI8ReQpDnoiok/x9tTD6aZ2OGfQ6+Ps6HyPyFIY8\nEVEnaX1UCA02OR0LDQ7kVfbkdbzwjoioC+LDhwG4dg6+ur4RBr0OocGB4noib2LIExF1gUqpRFJE\nMGLDhvI+eepxGPJERN1A66NCkKGPt8sgaoXn5ImIiCSKIU9ERCRRDHkiIiKJYsgTERFJFEOeiIhI\nohjyREREEsWQJyIikiiGPBERkUQx5ImIiCSKIU9ERCRRDHkiIiKJYsgTERFJFEOeiIhIohjyRERE\nEsWQJyIikiiGPBERkUQx5ImIiCRK7c43t1gsWLx4MRYsWACz2Yxnn30WZ86cQb9+/QAACxcuxIwZ\nMzB69GiMHz9efN327duhUqncWRoREZHkuS3krVYrUlNTMWXKlFbrn376adx///2t1vn6+iIrK8td\npRAREcmS26brNRoNtm7diqCgIHd9BBEREbXDbSGvVquh0+luWJ+dnY1HH30UK1asQFVVFQCgqakJ\nKSkpSEhIwLZt29xVEhERkay49Zz8Lz300EPo168f7rzzTmRmZmLz5s144YUXsHLlSsTExEChUMBs\nNmPixIkICQlp830Mhj5Qq9s/Z28y6bu7/F5Drr3LtW+AvcuRXPsG5N37zfJoyP/8/Hx4eDjWrl0L\nAEhMTBTXT548GRaLpd2Qr662tvs5JpMeFRX1XSu2l5Jr73LtG2Dvcuxdrn0D8u29s19sPHoL3bJl\ny1BaWgoAyM/Px/Dhw1FSUoKUlBQIgoDm5mYUFhZi+PDhniyLiIhIktx2JF9cXIy0tDSUlZVBrVYj\nJycHZrMZy5cvxy233II+ffpg/fr1CAgIwIABAxAXFwelUonw8HCMGTPGXWUREbXLZnegtsEGf18t\ntD68lZd6N4UgCIK3i7hZrqZq5DqdA8i3d7n2DbD37urd0dKCHbnnUGSpQFWdDUY/LUKDTYgPHwaV\nsmf9bhj3ufx67+x0vUfPyRMR9VQ7cs/hcMFFcflynU1cTooI9lZZRF3Ss76eEhF5gc3uQJGlwulY\nkaUSNrvDwxURdQ+GPBHJXm2DDVV1Nqdj1fWNqG1wPkbU0zHkiUj2/H21MPppnY4Z9Dr4+zofI+rp\nGPJEJHtaHxVCg01Ox0KDA3vsVfY2uwPl1VaeTqA28cI7IiIA8eHDAFw7B19d3wiDXofQ4EBxfU/i\ncLTgvw9besWdAORdLkP+7NmzWL16NaxWKw4ePIiMjAxMmzYNY8eO9UR9REQeoVIqkRQRjNiwoT3+\nPvn/+ugM7wSgDnH5le/FF1/EK6+8ApPp2lTWnDlzsH79ercXRkTkDVofFYIMfXpswNvsDvy9+Een\nY7wTgH7JZcir1WqMHDlSXB4yZAjUas7yExF5Q22DDRU1V52O8U4A+qUOhXxpaSkUCgUA4NixY+iF\nP5JHRCQJ/r5amPrd4nSMdwLQL7k8JF+1ahUWL16M8+fPY8KECRg4cCA2bNjgidqIiOgXtD4qTL7r\nVuzLK7lhrCffCUDe4TLkDQYDPvroI1RVVUGj0cDX19cTdRERURt+++BoWK829Yo7Aci7XIb8M888\ng3feeQdGo9ET9RARkQsqVe+5E4C8y2XIDx48GCtXrkRoaCh8fHzE9XFxcW4tjIiI2nf9TgCitrgM\nebvdDpVKhW+++abVeoY8ERFRz+Yy5HlPPBERUe/kMuTDwsLE2+d+7ujRo+6oh4iIiLqJy5D/7//+\nb/HfdrsdJ06cQGNjo1uLIiIioq5zGfIDBw5stTx48GAsXLgQ//Zv/+a2ooiIiKjrXIb8iRMnWi3/\n9NNP+J//+R+3FURERETdw2XIb9myRfy3QqGAr68v1q1b59aiiIiIqOtchnxWVlar5ZaWFij5vGIi\nIqIez2Va79mzB++++y4cDgcSExMxc+bMVhfjERERUc/kMuR37NiBuXPn4tNPP8Xw4cPx2Wef4cCB\nA56ojYiIiLrAZchrtVpoNBocO3YMs2fP5lQ9ERFRL9GhxF63bh0KCwtx9913o6ioCE1NTR16c4vF\ngoiICGRnZwMAnn32WTz44INITk5GcnKy+IM6+/btQ2xsLObOnYtdu3Z1rhMiIiJqxeWFdxs3bsQn\nn3yC5ORkqFQqlJWVdejqeqvVitTUVEyZMqXV+qeffhr3339/q+0yMjKwe/du+Pj4IC4uDpGRkejX\nr18n2iEiIqLrOjRdP3XqVNxxxx3Iy8vDhQsXEBAQ4PKNNRoNtm7diqCgoHa3O3XqFEJCQqDX66HT\n6TB+/HgUFhZ2vAMiIiJyymXI/+EPf0B5eTn+9a9/4dVXX0W/fv3wxz/+0eUbq9Vq6HS6G9ZnZ2fj\n0UcfxYoVK1BVVYXKyspWz6o3Go2oqKi4yTaIiIjol1xO11+9ehVTp07FG2+8AbPZjMTERBw+fLhT\nH/bQQw+hX79+uPPOO5GZmYnNmzcjNDS01TaCILh8H4OhD9RqVbvbmEz6TtUoBXLtXa59A+xdjuTa\nNyDv3m9Wh0K+qqoKOTk52LJlCwRBQG1tbac+7Ofn58PDw7F27VpERUWhsrJSXF9eXo5x48a1+z7V\n1dZ2x00mPSoq6jtVY28n197l2jfA3uXYu1z7BuTbe2e/2Licrn/wwQcxa9YsTJ48GbfeeisyMjJw\nzz33dOrDli1bhtLSUgBAfn4+hg8fjrFjx+L06dOoq6vDlStXUFhYiIkTJ3bq/YmIiOj/KISOzI//\nTF1dHfz8/FxuV1xcjLS0NJSVlUGtVqN///4wm83IzMzELbfcgj59+mD9+vUICAjAwYMH8dZbb0Gh\nUMBsNiMmJqbd93b1LU6u3/QA+fYu176B3tG7ze5AbYMN/r5aaH3aP9V2M3pD7+4g174B+fbe2SN5\nlyF/9uxZrF69GlarFQcPHkRGRgamTZuGsWPHduoDuwNDvm1y7V2ufQM9u3dHSwt25J5DkaUCVXU2\nGP20CA02IT58GFTd8MNaPbl3d5Jr34B8e3fbdP2LL76IV155BSaTCQAwZ84crF+/vlMfRkTysiP3\nHA4XXMTlOhsEAJfrbDhccBE7cs95uzQiWXAZ8mq1GiNHjhSXhwwZArXa5fV6RCRzNrsDRRbnt8MW\nWSphszs8XBGR/HQo5EtLS6FQKAAAx44d69BtbkQkb7UNNlTV2ZyOVdc3orbB+RgRdR+Xh+SrVq3C\n4sWLcf78eUyYMAEDBw7Ehg0bPFEbEfVi/r5aGP20uOwk6A16Hfx9tV6oikheXIa8wWDARx99hKqq\nKmg0Gvj6+nqiLiLq5bQ+KoQGm3C44OINY6HBgd16lT0ROedyuv6ZZ54BcO3nZhnwRHQz4sOHIWLi\n7Qjw00GpAAL8dIiYeDviw4d5uzQiWXB5JD948GCsXLkSoaGh8PHxEdfHxcW5tTAi6v1USiWSIoIR\nGzbULffJE1H7XIa83W6HSqXCN99802o9Q56IOkrro0KQoY+3yyCSHZchz3viiYiIeqc2z8l///33\niI2Nxfjx4/H73/++1UNkiIiIqOdrM+RffvllPPnkk8jLy8OsWbOwceNGT9ZFREREXdRmyDscDoSF\nhaFv376Ii4tDWVmZJ+siIiKiLmoz5K//wl1by0RERNSztXnhnc1mE5/97mx50KBB7q2MiIiIuqTN\nkK+oqMCCBQta/U79Y489BuDaUf1nn33m/uqIiIio09oM+dzcXE/WQURERN3M5c/aEhERUe/EkCci\nIpIohjwREZFEtXlOfvPmze2+cOnSpd1eDBEREXWfNkO+ubkZAHDhwgVcuHABEydOREtLC7766iuM\nGjXKYwUSERFR57QZ8suXLwcALFq0CLt27YJKde3xkHa7HStWrPBMdURERNRpLs/J//jjj63ulVco\nFPjhhx/cWhQRERF1nctHzc6YMQNRUVEYPXo0FAoFvvvuO8ycOdMTtREREVEXuAz5FStW4De/+Q0s\nFgsEQcCyZcswbNgwT9RGREREXeByut7hcODrr7/GV199hZMnT+Ls2bMdfnOLxYKIiAhkZ2e3Wp+X\nl4cRI0aIy6NHj0ZycrL4n8PhuIkWiIiIyBmXR/KpqamoqqrCPffcA0EQcODAAXz99dd4/vnn232d\n1WpFamoqpkyZ0mq9zWZDZmYmTCaTuM7X1xdZWVmdbIGIiIiccXkkf+7cOWzatAnz58+H2WxGRkYG\nvv32W5dvrNFosHXrVgQFBbVa/8YbbyApKQkajabzVRMREZFLLkPebrejpaVFXHY4HB2aTler1dDp\ndK3WnT9/HmfPnsXs2bNbrW9qakJKSgoSEhKwbdu2jtZORERE7XA5XR8WFoa4uDhMmjQJAJCfn485\nc+Z06sPWr1/vdJp/5cqViImJgUKhgNlsxsSJExESEtLm+xgMfaBWq9r9LJNJ36kapUCuvcu1b4C9\ny5Fc+wbk3fvNUgg/vwm+DV9//TVOnToFhUKBcePGYcyYMR3+gPT0dBgMBkRGRmL+/PkwGo0AgG+/\n/Rbjxo274aK8DRs2YOjQoYiNjW3zPSsq6tv9TJNJ73IbqZJr73LtG2Dvcuxdrn0D8u29s19sOvSA\nmubmZrS0tKClpaXTV773798fhw8fxs6dO7Fz504EBQUhOzsbJSUlSElJgSAIaG5uRmFhIYYPH96p\nzyAiIqL/43K6/i9/+Qu++OILTJgwAQDw0ksvYdasWXj88cfbfV1xcTHS0tJQVlYGtVqNnJwcpKen\no1+/fq22u+OOOzBgwADExcVBqVQiPDz8pmYKiIiIyDmX0/VJSUnIzs6GUnntoL+5uRlmsxnvvfee\nRwp0htP1bZNr73LtG2Dvcuxdrn0D8u3dbdP1LS0tYsAD166aVygUnfowIiIi8hyX0/V33XUXFi1a\nhHvvvRcA8OWXX7Z75TsRERGGYJeMAAATZklEQVT1DC5DfvXq1Thw4IB4dX1MTMwN97kTERFRz9Nm\nyJeWlor/HjNmTKuL4S5evIhBgwa5tzIiIiLqkjZD/rHHHmvzRQqFAp999plbCiIi97LZHahtsMHf\nVwutT/s/KkVEvVubIZ+bm+vJOojIzRwtLdiRew5FlgpU1dlg9NMiNNiE+PBhUCk79JMZRNTLtHtO\n/uzZszCZTAgICMC7776Lzz//HMHBwXjiiSdu+F16IurZduSew+GCi+Ly5TqbuJwUEeytsojIjdr8\n+v7aa6/hqaeewrx58/Dmm2/i66+/RlxcHJqamvDCCy94skYi6iKb3YEiS4XTsSJLJWz2zv2SJRH1\nbG0eyf/973/HgQMHUF1djQceeACff/451Go1Zs6ciYSEBE/WSERdVNtgQ1WdzelYdX0jahtsCDL0\n8XBVRORubR7J33LLLVAqlQgICMCwYcOgVv/f9wEfHx+PFEdE3cPfVwujn9bpmEGvg7+v8zEi6t06\ndLWN8hcX5fAX74h6F62PCqHBJqdjocGBvMqeSKLanK4vKirCjBkzAACXL18W/y0IAqqrqz1RGxF1\no/jwYQCunYOvrm+EQa9DaHCguJ6IpKfNkD948KAn6yAiN1MplUiKCEZs2FDeJ08kE22G/MCBAz1Z\nBxF5iNZHxYvsiGSCv4BBREQkUQx5IiIiiWLIExERSRRDnoiISKIY8kRERBLFkCciIpIohjwREZFE\nMeSJiIgkiiFPREQkUQx5IiIiiWLIExERSZRbQ95isSAiIgLZ2dmt1ufl5WHEiBHi8r59+xAbG4u5\nc+di165d7iyJiIhINtp8QE1XWa1WpKamYsqUKa3W22w2ZGZmwmQyidtlZGRg9+7d8PHxQVxcHCIj\nI9GvXz93lUZERCQLbjuS12g02Lp1K4KCglqtf+ONN5CUlASNRgMAOHXqFEJCQqDX66HT6TB+/HgU\nFha6qywiIiLZcFvIq9Vq6HS6VuvOnz+Ps2fPYvbs2eK6yspKGI1GcdloNKKiosJdZREREcmG26br\nnVm/fj2ef/75drcRBMHl+xgMfaBWq9rdxmTS31RtUiLX3uXaN8De5UiufQPy7v1meSzkL126hJKS\nEjzzzDMAgPLycpjNZixbtgyVlZXiduXl5Rg3bly771VdbW133GTSo6KivutF90Jy7V2ufQPsXY69\ny7VvQL69d/aLjcdCvn///jh8+LC4HB4ejuzsbDQ2NuL5559HXV0dVCoVCgsLsXr1ak+VRUREJFlu\nC/ni4mKkpaWhrKwMarUaOTk5SE9Pv+GqeZ1Oh5SUFCxcuBAKhQJLliyBXs+pGCIioq5SCB05Cd7D\nuJqqket0DiDf3uXaN8De5di7XPsG5Nt7Z6fr+Yt3REREEsWQJyIikiiGPBERkUQx5ImIiCSKIU9E\nRCRRDHkiIiKJYsgTERFJFEOeiIhIohjyREREEsWQJyIikiiGPBERkUQx5ElybHYHyqutsNkd3i6F\niMirPPaoWSJ3c7S0YEfuORRZKlBVZ4PRT4vQYBPiw4dBpeT3WSKSH4Y8ScaO3HM4XHBRXL5cZxOX\nkyKCvVUWEZHX8PCGJKGxqRlFlgqnY0WWSk7dE5EsMeRJEqrrbKiqszkfq29EbYPzMSIiKWPIkyQY\n/LQw+mmdj+l18Pd1PkZEJGUMeZIEnUaN0GCT07HQ4EBofVQeroiIyPt44R1JRnz4MADXzsFX1zfC\noNchNDhQXE9EJDcMeZIMlVKJpIhgxIYNRW2DDf6+Wh7BE5GsMeRJcrQ+KgQZ+ni7DCIir+M5eSIi\nIoliyBMREUkUQ56IiEiiGPJEREQS5dYL7ywWCxYvXowFCxbAbDajqKgIGzZsgFqthkajwZ/+9CcY\njUaMHj0a48ePF1+3fft2qFS8KpqIiKgr3BbyVqsVqampmDJlirhu27Zt2LBhAwYNGoTNmzdj586d\nWLRoEXx9fZGVleWuUoiIiGTJbdP1Go0GW7duRVBQkLhu06ZNGDRoEARBwKVLlzBgwAB3fTwREZHs\nuS3k1Wo1dDrdDeuPHz+O6OhoVFZWIiYmBgDQ1NSElJQUJCQkYNu2be4qiYiISFYUgiAI7vyA9PR0\nGAwGmM1mcZ0gCNi4cSP0ej0WLVqEv/3tb4iJiYFCoYDZbMa6desQEhLS5ns2NzugVvOcPRERUXs8\n+ot3n376KSIjI6FQKBAVFYX09HQAQGJiorjN5MmTYbFY2g356mpru59jMulRUVHfPUX3MnLtXa59\nA+xdjr3LtW9Avr2bTPpOvc6jt9Clp6fju+++AwCcOnUKQ4YMQUlJCVJSUiAIApqbm1FYWIjhw4d7\nsiwiIiJJctuRfHFxMdLS0lBWVga1Wo2cnBy89NJLWLduHVQqFXQ6HTZs2ICAgAAMGDAAcXFxUCqV\nCA8Px5gxY9xVFhERkWy4/Zy8O7iaqpHrdA4g397l2jfA3uXYu1z7BuTbe6+YriciIiLPYcgTERFJ\nFEOeiIhIohjyREREEsWQJyIikiiGPBERkUQx5ImIiCSKIU9ERCRRDHkiIiKJYsgTERFJFEOeiIhI\nohjy5FY2uwPl1VbY7A5vl0JEJDsefZ48yYejpQU7cs+hyFKBqjobjH5ahAabEB8+DColv1sSEXkC\nQ57cYkfuORwuuCguX66zictJEcHeKouISFZ4SEXdzmZ3oMhS4XSsyFLJqXsiIg9hyFO3q22woarO\n5nSsur4RtQ3Ox4iIqHsx5Knb+ftqYfTTOh0z6HXw93U+RkRE3YshT91O66NCaLDJ6VhocCC0PioP\nV0REJE+88I7cIj58GIBr5+Cr6xth0OsQGhworiciIvdjyJNbqJRKJEUEIzZsKGobbPD31fIInojI\nwxjy5FZaHxWCDH28XQYRkSzxnDwREZFEMeSJiIgkiiFPREQkUQx5IiIiiXJryFssFkRERCA7OxsA\nUFRUhMTERCQnJ2PhwoWoqqoCAOzbtw+xsbGYO3cudu3a5c6SiIiIZMNtIW+1WpGamoopU6aI67Zt\n24YNGzYgKysLoaGh2LlzJ6xWKzIyMrB9+3ZkZWXh7bffRk1NjbvKIiIikg23hbxGo8HWrVsRFBQk\nrtu0aRMGDRoEQRBw6dIlDBgwAKdOnUJISAj0ej10Oh3Gjx+PwsJCd5VFREQkG24LebVaDZ1Od8P6\n48ePIzo6GpWVlYiJiUFlZSWMRqM4bjQaUVHh/AlmRERE1HEe/zGc++67D9OnT8fGjRuRmZmJgQMH\nthoXBMHlexgMfaBWt//raSaTvkt19mZy7V2ufQPsXY7k2jcg795vlkdD/tNPP0VkZCQUCgWioqKQ\nnp6O0NBQVFZWituUl5dj3Lhx7b5PdbW13XGTSY+Kivpuqbm3kWvvcu0bYO9y7F2ufQPy7b2zX2w8\negtdeno6vvvuOwDAqVOnMGTIEIwdOxanT59GXV0drly5gsLCQkycONGTZREREUmS247ki4uLkZaW\nhrKyMqjVauTk5OCll17CunXroFKpoNPpsGHDBuh0OqSkpGDhwoVQKBRYsmQJ9HpOxRAREXWVQujI\nSfAextVUjVyncwD59i7XvgH2Lsfe5do3IN/ee8V0PREREXkOQ56IiEiiGPJEREQSxZAnIiKSKIY8\nAJvdgfJqK2x2h7dLISIi6jYe/8W7nsTR0oIduedQZKlAVZ0NRj8tQoNNiA8fBpWS33+IiKh3k3XI\n78g9h8MFF8Xly3U2cTkpIthbZREREXUL2R6u2uwOFFmcPwinyFLJqXsiIur1ZBvytQ02VNXZnI5V\n1zeitsH5GBERUW8h25D399XC6Kd1OmbQ6+Dv63yMiIiot5BtyGt9VAgNNjkdCw0OhNan/UfZEhER\n9XSyvvAuPnwYgGvn4KvrG2HQ6xAaHCiuJyIi6s1kHfIqpRJJEcGIDRuK2gYb/H21PIInIiLJkHXI\nX6f1USHI0MfbZRAREXUr2Z6TJyIikjqGPBERkUQx5ImIiCSKIU9ERCRRDHkiIiKJYsgTERFJFEOe\niIhIohjyREREEqUQBEHwdhFERETU/XgkT0REJFEMeSIiIoliyBMREUkUQ56IiEiiGPJEREQSxZAn\nIiKSKEmEfHNzM1atWoXExETMmzcPBQUFN2yzb98+xMbGYu7cudi1a5cXqnSPr776ClOmTMGRI0ec\njo8ePRrJycnifw6Hw8MVuo+r3qW6z+12O1JSUpCYmAiz2YzS0tIbtpHafn/llVcQHx+PhIQEfPPN\nN63GvvzyS8TFxSE+Ph4ZGRleqtB92us9PDwcSUlJ4n6+dOmSl6p0D4vFgoiICGRnZ98wJuX93l7f\nN73PBQnYvXu3sGbNGkEQBMFisQixsbGtxq9cuSLMmjVLqKurE65evSo88MADQnV1tRcq7V4XLlwQ\nFi1aJCxevFjIzc11us3dd9/t4ao8w1XvUt3ngiAIe/bsEdauXSsIgiDk5eUJTz311A3bSGm/5+fn\nC7///e8FQRCEc+fOCfPmzWs1Pnv2bOGHH34QHA6HkJiYKHz//ffeKNMtXPV+//33Cw0NDd4oze2u\nXLkimM1m4fnnnxeysrJuGJfqfnfV983uc0kcycfExOC5554DABiNRtTU1LQaP3XqFEJCQqDX66HT\n6TB+/HgUFhZ6o9RuZTKZsHnzZuj1em+X4nGuepfqPgeAEydOIDIyEgBw7733Sqavtpw4cQIREREA\ngKFDh6K2thYNDQ0AgNLSUvj7++PWW2+FUqlEWFgYTpw44c1yu1V7vUudRqPB1q1bERQUdMOYlPd7\ne313hiRC3sfHB1qtFgDw9ttv49e//nWr8crKShiNRnHZaDSioqLCozW6wy233AKVStXuNk1NTUhJ\nSUFCQgK2bdvmocrcz1XvUt3nQOvelEolFAoFmpqaWm0jpf1eWVkJg8EgLv98X1ZUVEh2PwPt937d\nmjVrkJiYiI0bN0KQ0A+YqtVq6HQ6p2NS3u/t9X3dzexzdXcW5wm7du264fzqsmXLMH36dLz77rs4\nc+YM3njjjXbfozf+D6G9vtuzcuVKxMTEQKFQwGw2Y+LEiQgJCXFnqd2us73/XG/c54Dz3k+dOtVq\n2VlvUtjvbemt+7I7/LL3J598EtOnT4e/vz+WLFmCnJwcREdHe6k68oSb3ee9LuTnzp2LuXPn3rB+\n165dyM3NxZYtW+Dj49NqLCgoCJWVleJyeXk5xo0b5/Zau1NbfbuSmJgo/nvy5MmwWCy97v/sO9O7\nFPY54Lz3Z599FhUVFRg5ciTsdjsEQYBGo2m1jRT2+3XO9qXJZHI6dunSpW6b5uwJ2usdAB5++GHx\n3/fddx8sFossQl7q+709N7vPJTFdX1paivfeew+bN28Wp+1/buzYsTh9+jTq6upw5coVFBYWYuLE\niV6o1LNKSkqQkpICQRDQ3NyMwsJCDB8+3NtleYSU9/nUqVNx8OBBAMCRI0dwzz33tBqX2n6fOnUq\ncnJyAABnzpxBUFAQfH19AQC33347GhoacPHiRTQ3N+PIkSOYOnWqN8vtVu31Xl9fj4ULF4qnak6e\nPNmr9/PNkPp+b0tn9rkknkL3+uuvY//+/bjtttvEdW+99Ra2b9+OSZMmITQ0FAcPHsRbb70lTl/G\nxMR4seLucfToUbz11lsoKSmB0WiEyWTCf/3XfyEzM1Ps+09/+hP+/ve/Q6lUIjw8HE888YS3y+4W\nHeldivscABwOB55//nn861//gkajwauvvopbb71V0vt948aNKCgogEKhwJo1a/Dtt99Cr9cjMjIS\nJ0+exMaNGwEAs2bNwsKFC71cbfdqr/e3334bH374IbRaLUaNGoX/+I//gEKh8HbJ3aK4uBhpaWko\nKyuDWq1G//79ER4ejttvv13S+91V3ze7zyUR8kRERHQjSUzXExER0Y0Y8kRERBLFkCciIpIohjwR\nEZFEMeSJiIgkiiFPRKLy8nKMGjUKmZmZ3i6FiLoBQ56IRB9++CGGDh2KPXv2eLsUIuoGDHkiEr3/\n/vtYvXo1rl69Kj7d7tixY4iJiUFycjIyMzNx3333AQBqa2uxfPlyPProo3jkkUfw0UcfebN0InKC\nIU9EAK79RGZzczMmT56Mhx9+GHv27IEgCFizZg02bNiArKws1NfXi9v/+c9/xvTp0/HOO+8gOzsb\nmzZtQlVVlRc7IKJfYsgTEQBg9+7d+M1vfgOFQoFHHnkEBw4cwI8//gir1YqRI0cCAKKiosTt8/Pz\n8be//Q3Jycl4/PHHoVarcfHiRW+VT0RO9Lqn0BFR92toaMChQ4dw66234tNPPwUAtLS0ID8/v9Xv\nYqtUKvHfGo0Ga9as6bVPtyOSAx7JExE+/vhjTJo0CZ988gn27t2LvXv34sUXX8QHH3wApVKJkpIS\nAMChQ4fE10yYMAEHDhwAADQ2NmLt2rVobm72Sv1E5BxDnoiwe/fuVs+gB65Nzf/zn//EY489hiVL\nlmDhwoXQaDRQq69NAC5duhQXLlxAYmIi5s+fj1GjRoljRNQz8Cl0RNSuw4cPY8SIERg0aBAOHTqE\nHTt24K233vJ2WUTUAfzaTUTtamlpwbJly+Dr6wuHw4G1a9d6uyQi6iAeyRMREUkUz8kTERFJFEOe\niIhIohjyREREEsWQJyIikiiGPBERkUQx5ImIiCTq/wPbxExXPgQFNAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dWaHw7mPl9o2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1fd6893b-fc79-40b0-9348-b3e2537105a6"
      },
      "cell_type": "code",
      "source": [
        "# Set inital hyperparameters\n",
        "alpha = .01\n",
        "iterations = 2000\n",
        "n = len(y)\n",
        "np.random.seed(42)\n",
        "theta = [0,0]\n",
        "\n",
        "#Calculate Predictions\n",
        "prediction = np.dot(X_linalg, theta)\n",
        "print(\"Prediction: \\n\", prediction)\n",
        "\n",
        "#Calculate Error\n",
        "error = prediction - y\n",
        "print(\"Error: \\n\", error)\n",
        "\n",
        "#Update Theta List Values\n",
        "theta = theta - (alpha * (1/n) * np.dot(X.T, error))\n",
        "print(\"Theta: \\n\", theta)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Error: \n",
            " [-132. -143. -153. -162. -154. -168. -137. -149. -159. -128. -166.]\n",
            "Theta: \n",
            " [0.12715857 0.12715857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "StYSKyk_mUA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c58385e-386f-42a3-a72b-c29293982f48"
      },
      "cell_type": "code",
      "source": [
        "#Minimal Gradient-Descent Implementation\n",
        "def gradient_descent(X, y, theta, iterations, alpha):\n",
        "  for _ in range(iterations):\n",
        "    prediction = np.dot(X,theta)\n",
        "    error = prediction - y\n",
        "    updates = (alpha * (1/n) * np.dot(X.T,error))\n",
        "    theta = theta - updates\n",
        "  return theta\n",
        "\n",
        "gradient_descent(X_linalg, y, theta, iterations, alpha)\n",
        "\n",
        "#Equals what we got with sklearn"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([150.09090881,  12.71585673])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "x5mavmEho7ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95078ce3-c63e-4ac1-ed13-828ac35f5f5c"
      },
      "cell_type": "code",
      "source": [
        "# Now on to using all 3 variables\n",
        "\n",
        "# Normalize all the data\n",
        "\n",
        "df1 = (df - df.mean())/df.std()\n",
        "df1.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.327593</td>\n",
              "      <td>-1.147033</td>\n",
              "      <td>-1.270594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.520363</td>\n",
              "      <td>-0.379020</td>\n",
              "      <td>-0.635297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.213482</td>\n",
              "      <td>0.498710</td>\n",
              "      <td>-0.057754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.873943</td>\n",
              "      <td>1.157007</td>\n",
              "      <td>0.924069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.286867</td>\n",
              "      <td>0.169561</td>\n",
              "      <td>0.057754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          y       age    weight\n",
              "0 -1.327593 -1.147033 -1.270594\n",
              "1 -0.520363 -0.379020 -0.635297\n",
              "2  0.213482  0.498710 -0.057754\n",
              "3  0.873943  1.157007  0.924069\n",
              "4  0.286867  0.169561  0.057754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "HZ4yTuWypNGQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df1.iloc[:,1:3]\n",
        "\n",
        "X_linalg = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "y = df1['y'].values\n",
        "theta = [0,0,0]\n",
        "\n",
        "alpha = .01\n",
        "iterations = 9000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QytG5M1Zrq4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2405682-4ce6-4fd9-87c2-3f3a83870a71"
      },
      "cell_type": "code",
      "source": [
        "#sklearn results\n",
        "\n",
        "# Fit Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Assign coefficient and intercept to variables (beta_1, and beta_0)\n",
        "beta_1 = model.coef_\n",
        "beta_0 = model.intercept_\n",
        "\n",
        "print(\"beta_1: \", beta_1)\n",
        "print(\"beta_0: \", beta_0)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta_1:  [0.57616409 0.4254835 ]\n",
            "beta_0:  -2.949017333121613e-16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a2_HX5UjrEOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70e06f09-2aa7-46a3-a424-2fee88221c67"
      },
      "cell_type": "code",
      "source": [
        "#Calculate Cost\n",
        "def computeCost(X, y, theta):\n",
        "  tobesummed = (alpha * (1/n) * np.dot(X.T,error))\n",
        "  return np.sum(tobesummed)/(2 * len(X))\n",
        "\n",
        "computeCost(X,y,theta)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.01097612956575818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "jpHLwJIBtdVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc8b2b73-d102-4fa5-f8c0-9d09c15e4bb2"
      },
      "cell_type": "code",
      "source": [
        "#gradient descent\n",
        "def gradient_descent(X, y, theta, iterations, alpha):\n",
        "  for _ in range(iterations):\n",
        "    prediction = np.dot(X,theta)\n",
        "    error = prediction - y\n",
        "    updates = (alpha * (1/n) * np.dot(X.T,error))\n",
        "    theta = theta - updates\n",
        "  return theta\n",
        "\n",
        "gradient_descent(X_linalg, y, theta, iterations, alpha)\n",
        "\n",
        "#Had to increase iterations to 10k to get pretty close to sklearn results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.77606221e-16,  5.75252930e-01,  4.26394659e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "RCs6EmWhYPM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch Goals\n",
        "\n",
        "If you happen upon the most useful resources for accomplishing this challenge first, I want you to spend time today studying other variations of Gradient Descent-Based Optimizers.\n",
        "\n",
        "- Try and write a function that can perform gradient descent for arbitarily large (in dimensionality) multiple regression models. \n",
        "- Create a notebook for yourself exploring these topics\n",
        "- How do they differ from the \"vanilla\" gradient descent we explored today\n",
        "- How do these different gradient descent-based optimizers seek to overcome the challenge of finding the global minimum among various local minima?\n",
        "- Write a blog post that reteaches what you have learned about these other gradient descent-based optimizers.\n",
        "\n",
        "[Overview of GD-based optimizers](http://ruder.io/optimizing-gradient-descent/)\n",
        "\n",
        "[Siraj Raval - Evolution of Gradient Descent-Based Optimizers](https://youtu.be/nhqo0u1a6fw)"
      ]
    }
  ]
}