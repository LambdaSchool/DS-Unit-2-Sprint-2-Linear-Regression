{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chadeowen/DS-Unit-2-Sprint-2-Linear-Regression/blob/master/module3-gradient-descent/Gradient_Descent_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Qhm0Y_jqXKRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Implementation Challenge!!\n",
        "\n",
        "## Use gradient descent to find the optimal parameters of a **multiple** regression model. (We only showed an implementation for a bivariate model during lecture.)\n",
        "\n",
        "A note: Implementing gradient descent in any context is not trivial, particularly the step where we calculate the gradient will change based on the number of parameters that we're trying to optimize for. You will need to research what the gradient of a multiple regression model looks like. This challenge is pretty open-ended but I hope it will be thrilling. Please work together, help each other, share resources and generally expand your understanding of gradient descent as you try and achieve this implementation. \n",
        "\n",
        "## Suggestions:\n",
        "\n",
        "Start off with a model that has just two $X$ variables You can use any datasets that have at least two x variables. Potential candidates might be the blood pressure dataset that we used during lecture on Monday: [HERE](https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/excel/mlr02.xls) or any of the housing datasets. You would just need to select from them the two varaibles $x$ variables and one y variable that you want to work with that you most want to work with. \n",
        "\n",
        "Use Sklearn to find the optimal parameters of your model first. (like we did during the lecture.) So that you can compare the parameter estimates of your gradient-descent linear regression to the estimates of OLS linear regression. If implemented correctly they should be nearly identical.\n",
        "\n",
        "Becoming a Data Scientist is all about striking out into the unknown, getting stuck and then researching and fighting and learning until you get yourself unstuck. Work together! And fight to take your own learning-rate fueled step towards your own optimal understanding of gradient descent! \n"
      ]
    },
    {
      "metadata": {
        "id": "6lXymobL2c7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vv2rDGVd9SlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d226bea6-a36e-433e-cc08-46d6e5834dd3"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/excel/mlr02.xls')\n",
        "df = df.rename(columns={'X1':'blood_pressure', \"X2\":'age', \"X3\":'weight'})\n",
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>132</td>\n",
              "      <td>52</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>143</td>\n",
              "      <td>59</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153</td>\n",
              "      <td>67</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>162</td>\n",
              "      <td>73</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154</td>\n",
              "      <td>64</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   blood_pressure  age  weight\n",
              "0             132   52     173\n",
              "1             143   59     184\n",
              "2             153   67     194\n",
              "3             162   73     211\n",
              "4             154   64     196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "Ghv8_Qk3AkNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "50542484-fd05-4428-a7a1-e5d74c2b4661"
      },
      "cell_type": "code",
      "source": [
        "# Test run with Bivariate\n",
        "\n",
        "# Calculate parameters using sklearn and compare to our Gradient Descent Method\n",
        "\n",
        "# Create X array\n",
        "X = df['age'].values[:, np.newaxis]\n",
        "\n",
        "# Normalize X values\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Turn X into a matrix by stacking the arrays\n",
        "X_linalg = np.c_[np.ones(X.shape[0]), X] \n",
        "\n",
        "print('X Matrix: ', X_linalg)\n",
        "\n",
        "# Create y variable list\n",
        "y = df['blood_pressure'].values\n",
        "\n",
        "# Fit Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Assign coefficient and intercept to variables (beta_1, and beta_0)\n",
        "beta_1 = model.coef_[0]\n",
        "beta_0 = model.intercept_\n",
        "\n",
        "print(\"\\nbeta_1: \", beta_1)\n",
        "print(\"beta_0: \", beta_0)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Matrix:  [[ 1.         -1.20301838]\n",
            " [ 1.         -0.39751912]\n",
            " [ 1.          0.52305147]\n",
            " [ 1.          1.21347941]\n",
            " [ 1.          0.1778375 ]\n",
            " [ 1.          1.32855074]\n",
            " [ 1.         -0.97287574]\n",
            " [ 1.         -0.16737647]\n",
            " [ 1.          0.29290882]\n",
            " [ 1.         -1.89344632]\n",
            " [ 1.          1.09840809]]\n",
            "\n",
            "beta_1:  12.715856751330023\n",
            "beta_0:  150.0909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAZu1jJoAkbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "cf28ed42-0035-499c-f0a4-476b918f7c33"
      },
      "cell_type": "code",
      "source": [
        "# Plot y vs standardized X\n",
        "\n",
        "plt.scatter(X,y)\n",
        "\n",
        "plt.ylabel(\"Blood Pressure\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.title(\"Blood Pressure vs Age\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFnCAYAAACl2jDXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuKS/h3MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "eXsz9kefAkp5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "80e04e6c-3d65-405c-ff2e-51627fad71a8"
      },
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "alpha = .01\n",
        "iterations = 2000\n",
        "n = len(y)\n",
        "np.random.seed(42)\n",
        "theta = [0,0]\n",
        "\n",
        "# Calculate Predictions\n",
        "prediction = np.dot(X_linalg, theta)\n",
        "print(\"Prediction: \\n\", prediction)\n",
        "\n",
        "# Calculate Error\n",
        "error = prediction - y\n",
        "print(\"\\nError: \\n\", error)\n",
        "\n",
        "# Update Theta List Values\n",
        "theta = theta - (alpha * (1/n) * np.dot(X.T, error))\n",
        "print(\"\\nTheta: \\n\", theta)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: \n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "\n",
            "Error: \n",
            " [-132. -143. -153. -162. -154. -168. -137. -149. -159. -128. -166.]\n",
            "\n",
            "Theta: \n",
            " [0.12715857 0.12715857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VRzn--VaAk4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b6526d4-b003-4cad-8cc3-f4f490740455"
      },
      "cell_type": "code",
      "source": [
        "# Minimal Gradient-Descent Implementation\n",
        "def gradient_descent(X, y, theta, iterations, alpha):\n",
        "  for _ in range(iterations):\n",
        "    prediction = np.dot(X,theta)\n",
        "    error = prediction - y\n",
        "    updates = (alpha * (1/n) * np.dot(X.T,error))\n",
        "    theta = theta - updates\n",
        "  return theta\n",
        "\n",
        "gradient_descent(X_linalg, y, theta, iterations, alpha)\n",
        "\n",
        "# Confirm with sklearn"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([150.09090881,  12.71585673])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "pcs6dXYOAlII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "278a9ec2-00d6-4e6c-b969-654b326703b5"
      },
      "cell_type": "code",
      "source": [
        "# Multivariate\n",
        "\n",
        "# Normalize entire dataset\n",
        "\n",
        "df1 = (df - df.mean())/df.std()\n",
        "df1.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.327593</td>\n",
              "      <td>-1.147033</td>\n",
              "      <td>-1.270594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.520363</td>\n",
              "      <td>-0.379020</td>\n",
              "      <td>-0.635297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.213482</td>\n",
              "      <td>0.498710</td>\n",
              "      <td>-0.057754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.873943</td>\n",
              "      <td>1.157007</td>\n",
              "      <td>0.924069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.286867</td>\n",
              "      <td>0.169561</td>\n",
              "      <td>0.057754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   blood_pressure       age    weight\n",
              "0       -1.327593 -1.147033 -1.270594\n",
              "1       -0.520363 -0.379020 -0.635297\n",
              "2        0.213482  0.498710 -0.057754\n",
              "3        0.873943  1.157007  0.924069\n",
              "4        0.286867  0.169561  0.057754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "CAQZImmUDYX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create X matrix\n",
        "X = df1.iloc[:,1:3]\n",
        "\n",
        "# Turn X into a matrix by stacking arrays\n",
        "X_linalg = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "# Create y variable list\n",
        "y = df1['blood_pressure'].values\n",
        "\n",
        "# Set hyperameters\n",
        "theta = [0,0,0]\n",
        "alpha = .1\n",
        "iterations = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGtaOtReDYn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14c98118-7efb-4b8c-e5d4-8d710b73b31a"
      },
      "cell_type": "code",
      "source": [
        "# Fit Model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Assign coefficient and intercept to variables (beta_1, and beta_0)\n",
        "beta_1 = model.coef_\n",
        "beta_0 = model.intercept_\n",
        "\n",
        "print(\"beta_1: \", beta_1)\n",
        "print(\"beta_0: \", beta_0)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "beta_1:  [0.57616409 0.4254835 ]\n",
            "beta_0:  -2.949017333121613e-16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "82l_GXd_DY5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1dee178-1774-4830-dfc7-286153503695"
      },
      "cell_type": "code",
      "source": [
        "# Calculate Cost\n",
        "def computeCost(X, y, theta):\n",
        "  tobesummed = (alpha * (1/n) * np.dot(X.T,error))\n",
        "  return np.sum(tobesummed)/(2 * len(X))\n",
        "\n",
        "computeCost(X,y,theta)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.1097612956575818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "_tWzF6IqXIIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "715d3447-02c3-4a5a-f9fc-68a469ba04af"
      },
      "cell_type": "code",
      "source": [
        "# Minimal Gradient-Descent Implementation\n",
        "def gradient_descent(X, y, theta, iterations, alpha):\n",
        "  for _ in range(iterations):\n",
        "    prediction = np.dot(X,theta)\n",
        "    error = prediction - y\n",
        "    updates = (alpha * (1/n) * np.dot(X.T,error))\n",
        "    theta = theta - updates\n",
        "  return theta\n",
        "\n",
        "gradient_descent(X_linalg, y, theta, iterations, alpha)\n",
        "\n",
        "# See iterations and alpha"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.78565050e-16,  5.76164087e-01,  4.25483502e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "RCs6EmWhYPM-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch Goals\n",
        "\n",
        "If you happen upon the most useful resources for accomplishing this challenge first, I want you to spend time today studying other variations of Gradient Descent-Based Optimizers.\n",
        "\n",
        "- Try and write a function that can perform gradient descent for arbitarily large (in dimensionality) multiple regression models. \n",
        "- Create a notebook for yourself exploring these topics\n",
        "- How do they differ from the \"vanilla\" gradient descent we explored today\n",
        "- How do these different gradient descent-based optimizers seek to overcome the challenge of finding the global minimum among various local minima?\n",
        "- Write a blog post that reteaches what you have learned about these other gradient descent-based optimizers.\n",
        "\n",
        "[Overview of GD-based optimizers](http://ruder.io/optimizing-gradient-descent/)\n",
        "\n",
        "[Siraj Raval - Evolution of Gradient Descent-Based Optimizers](https://youtu.be/nhqo0u1a6fw)"
      ]
    }
  ]
}