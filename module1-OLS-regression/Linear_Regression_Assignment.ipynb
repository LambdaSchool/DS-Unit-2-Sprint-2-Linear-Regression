{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "g_AhWOYeMfrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# King County Housing Data - Linear Regression\n",
        "\n",
        "Data for this assignment was obtained from Kaggle: <https://www.kaggle.com/harlfoxem/housesalesprediction>\n",
        "\n",
        "Complete the following challenges below to improve iteratively your home price estimation and practice implementing predictive linear regression models. "
      ]
    },
    {
      "metadata": {
        "id": "3kcL7V2SHAkp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bivariate Regression\n",
        "\n",
        "Pick the X variable that you think will be the most correlated with Y. \n",
        "\n",
        "Split your dataset into a 50-50 test-train-split (50% of data for training, and 50% for testing).\n",
        "\n",
        "Train a regression model using this single X and single Y variable. Once you have trained the model and obtained its coefficients, plot the points on a graph and fit your line of best fit to the graph.\n",
        "\n",
        "Report your Root Mean Squared Error and R-Squared for this model.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VOr4Yhqn1rh9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 uninstall seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ez_ZayUW2JzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# restart runtime after running cell\n",
        "!pip3 --no-cache-dir install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5gPYOmHMPAW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/kc_house_data.csv')\n",
        "pd.set_option('display.max_columns', 100)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DhBV6VTZGnQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = df['price']\n",
        "x = df['sqft_living']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5)\n",
        "\n",
        "# reshape x, y data to fit library expectations\n",
        "x_train = x_train.values.reshape(-1, 1)\n",
        "x_test = x_test.values.reshape(-1, 1)\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "print('Training data shape for x and y',x_train.shape, y_train.shape)\n",
        "print (' \\n\\nTesting data shape for x and y',x_test.shape, y_test.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEAc435KwTpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit to model\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "fit_model = model.fit(x_train, y_train)\n",
        "\n",
        "predictions_x = model.predict(y_test)\n",
        "predictions_y = model.predict(x_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCfUWtZAyf7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Coefficient for predicted sqft_living: \", \n",
        "      fit_model.coef_)\n",
        "\n",
        "print(\"\\nIntercept Value: \", fit_model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2mY9wA-uzCrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(x_train, y_train, color = 'orange')\n",
        "plt.plot(x_train, model.predict(x_train), color = 'cyan')\n",
        "plt.title('Size of home vs Price (Training set)')\n",
        "plt.xlabel('Squarefootage of home')\n",
        "plt.ylabel('Price of home')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3pP-t7W4iZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.scatter(x_test, y_test, color = 'orange')\n",
        "plt.plot(x_test, model.predict(x_test), color = 'cyan')\n",
        "plt.title('Size of home vs Price (Test set)')\n",
        "plt.xlabel('Squarefootage of home')\n",
        "plt.ylabel('Price of home')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnlRafQs42GW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Visualization of Linear Fitting Variance\n",
        "\n",
        "The variance of the test data set's linear best fit **looks** minimal compared to the training data's, so we can naively assume that it's a well fitting model. We should of course verify our results. "
      ]
    },
    {
      "metadata": {
        "id": "VwFHJJNA5UfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "housing_mse = mean_squared_error(y_test, predictions_y)\n",
        "\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % housing_mse)\n",
        "\n",
        "print('Root mean square error: %.2f' % np.sqrt(housing_mse))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(y_test, predictions_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyzsqLsD6wrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Don't trust your eyeballs, but do use them\n",
        "\n",
        "As you can see, the actual variance score is sub .5, which is a pretty significant amount of unexplained variance, but we should also  wonder if this is a result of our outliers. There is an incredibly large cluster of price to square footage with a large smattering of outliers, so we might actually be okay with not being able to explain a large amount of variance for the model. For example the training data goes all the way up to 14k square feet for a home, while the test data stops near 10k. However, that means we need to reasses either our data or the model itself. \n",
        "\n",
        "# Bane of a data scientist.\n",
        "\n",
        "It'd be awfully convenient to implicilty understand if all of your data is a valid representation of a population, in this case the housing market's price to home square footage. But there's no real way to know that from these two variables. There's no one to tell you to drop the outliers, or to try a different model, or to tweak your linear regression. So you have to decide for yourself. You can use your intuition, or you can use tools to help you decide. I'm not going to bother right this moment since we use more features in a moment.\n",
        "\n",
        "# Methods aside, what does it mean\n",
        "\n",
        "There is something we can determine from our visualizations compared to our variance score.\n",
        "Because the distance of so many high priced homes are so far away from the best plotted line, with the **vast majority ** appearing quite close to the linear fit, we could venture to say the model is accurate at predicting the price of a home that falls within our large cluster(although we need to remove the outliers, because it is skewing the linear fit, you can visually see that quite easily from the plots), and fails to predict homes with very large square footage. Luckily for whoever wants to use this model to sell a home, we have proof that the majority of home buyer's fit within a very finite set of parameters(considering only square footage as an indictator of price..)\n",
        "\n",
        "Which brings me to the next point, this is one variable out of many, and while we could run analysis on it all day, we really should be moving along to include more features. "
      ]
    },
    {
      "metadata": {
        "id": "7Y7hg7wYHGZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Two-variable Multiple Regression\n",
        "\n",
        "To ramp up slowly, pick a second X variable that you think will be the most correlated with Y. \n",
        "\n",
        "Split your dataset into a 50-50 test-train-split (50% of data for training, and 50% for testing).\n",
        "\n",
        "Train a regression model using these two X variables. Once you have trained the model and obtained its coefficients, plot the points on a graph and fit your **plane** of best fit to the graph.\n",
        "\n",
        "Report your Root Mean Squared Error and R-squared for this model."
      ]
    },
    {
      "metadata": {
        "id": "Ceoln3RCHPQy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "\n",
        "y = df['price']\n",
        "x = df.filter(['sqft_living','bedrooms'])\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5)\n",
        "\n",
        "# fit to model\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "fit_model = model.fit(x_train, y_train)\n",
        "\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "print(\"Coefficients: \", \n",
        "      fit_model.coef_)\n",
        "\n",
        "print(\"\\nIntercept Value: \", fit_model.intercept_)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cuUiJ5lKa14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "\n",
        "# Generate 3dim mesh data\n",
        "x_surf = np.arange(0, 12000, 2000)                # generate a mesh\n",
        "y_surf = np.arange(0, 10, 1)\n",
        "x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
        "\n",
        "# flatten to 1dim arrays\n",
        "exog = pd.core.frame.DataFrame({'SquareFeet': x_surf.ravel(), \n",
        "                                'Bedrooms': y_surf.ravel()})\n",
        "out = fit_model.predict(exog)\n",
        "\n",
        "\n",
        "plt3d = plt.gca(projection='3d')\n",
        "\n",
        "plt3d.plot_surface(x_surf, y_surf, out.reshape(x_surf.shape),\n",
        "                rstride=1,\n",
        "                cstride=1,\n",
        "                color='orange',\n",
        "                alpha = 0.4)\n",
        "\n",
        "\n",
        "\n",
        "ax.scatter(x_test['sqft_living'], x_test['bedrooms'], model.predict(x_test), \n",
        "           c='blue', marker='o',\n",
        "           alpha=1)\n",
        "\n",
        "ax.set_xlabel('Square Feet')\n",
        "ax.set_ylabel('Bedrooms')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOCVFacpYz1n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ugh. Something is wrong with the  z-axis being overwritten. They play nicely when rendered seperately, but not together. I think it's just a limitation of matplotlib, will look for another rendering library in the future. For now it's just broken."
      ]
    },
    {
      "metadata": {
        "id": "a0lvzsr9fKAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "predictions_x = model.predict(y_test)\n",
        "predictions_y = model.predict(x_test)\n",
        "\n",
        "housing_mse = mean_squared_error(y_test, predictions_y)\n",
        "\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % housing_mse)\n",
        "\n",
        "print('Root mean square error: %.2f' % np.sqrt(housing_mse))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(y_test, predictions_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LRAjm6sHOy-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multiple Regression\n",
        "\n",
        "Now using all available X variables, split your data into test and training datasets, train your model, obtain its coefficients, and report the Root Mean Squared Error and R-squared values."
      ]
    },
    {
      "metadata": {
        "id": "1gEl3jAyI_-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = df.drop(['price'])\n",
        "y = df['price']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "fit_model = model.fit(x_train, y_train)\n",
        "\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "print(\"Coefficients: \", \n",
        "      fit_model.coef_)\n",
        "\n",
        "print(\"\\nIntercept Value: \", fit_model.intercept_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-NfQXJwii7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions_x = model.predict(y_test)\n",
        "predictions_y = model.predict(x_test)\n",
        "\n",
        "housing_mse = mean_squared_error(y_test, predictions_y)\n",
        "\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % housing_mse)\n",
        "\n",
        "print('Root mean square error: %.2f' % np.sqrt(housing_mse))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % r2_score(y_test, predictions_y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95Ln3VLJJEH_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stretch Goals\n",
        "\n",
        "Pick from these stretch goals the tasks that you feel like will be the most beneficial for you. \n",
        "\n",
        "- Explore the concept of $R^2$, learn how it is calculated and how it relates to covariance, correlation, and variance. \n",
        "- Start to research Polynomial Regression and Log-Linear Regression (tomorrow's topics). Find a new regression dataset and try to implement one of these models. \n",
        "- Research \"Feature Engineering\" see what features you can engineer on the above dataset. How much are you able to improve your accuracy with feature engineering?\n",
        "- Further explore the concept of \"Model Validation\" - we'll spend a whole week on this soon. What other measures of model accuracy could we have used besides Root Mean Squared Error?\n",
        "- Write a blog post explaining the basics of Linear Regression.\n",
        "\n",
        "Remember to share your findings in the slack channel. :)\n"
      ]
    }
  ]
}